{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support Vector Machine - La partie Math\n",
    "\n",
    "## Cas linéaire\n",
    "\n",
    "$y$ est la sortie: la classe.\n",
    "$x$ est le vecteur d'entrée: les données.\n",
    "\n",
    "Il existe une fonction cible $f$ qu'on cherche à évaluer par apprentissage car notre intuition mathématique flanche...\n",
    "\n",
    "$$\n",
    "y = f(x)\n",
    "$$\n",
    "\n",
    "Pour un problème linéairement séparable:\n",
    "$$\n",
    "h(x) = w^T x + w_0 = 0\n",
    "$$\n",
    "\n",
    "Le but du jeu est de trouver $w^T$ et $w_0$: c'est l'équation de l'hyperplan séparateur.\n",
    "\n",
    "Après quelques calculs (pas forcément simples) on peut montrer que:\n",
    "\n",
    "$$\n",
    "h(x) = \\sum_{k=1}^p \\alpha_k l_k (x \\cdot x_k) + w_0\n",
    "$$\n",
    "\n",
    "## Cas non linéaire\n",
    "\n",
    "On introduit une fonction $\\phi$ qui transforme nos données dans un espace de plus grande dimension nommé: **espace de redescription**.\n",
    "\n",
    "$$\n",
    "h(x) = w^T \\phi(x) + w_0 = 0\n",
    "$$\n",
    "\n",
    "La solution précédente devient:\n",
    "\n",
    "$$\n",
    "h(x) = \\sum_{k=1}^p \\alpha_k l_k K(x_k, x) + w_0\n",
    "$$\n",
    "\n",
    "avec\n",
    "\n",
    "$$\n",
    "K(x_i, x_j) = \\phi^T(x_i) \\phi(x_j)\n",
    "$$\n",
    "\n",
    "**La force du kernel trick**\n",
    "\n",
    "En pratique on choisit juste la fonction $K$ (et non pas $\\phi$) et on remplace le calcul du produit scalaire en grande dimension $x . x_k$ (très coûteux en temps de calcul) par l'évaluation de la fonction $K$ dans l'espace d'origin.\n",
    "\n",
    "## Choix de K\n",
    "\n",
    "Le premier noyau est le noyau linéaire:\n",
    "\n",
    "$$\n",
    "K(x_i, x_j) = x^T_i x_j\n",
    "$$\n",
    "\n",
    "Le noyau polynomial:\n",
    "\n",
    "$$\n",
    "K(x_i, x_j) = (x_i^T x_j + 1)^d\n",
    "$$\n",
    "\n",
    "Le noyau gaussien:\n",
    "\n",
    "$$\n",
    "K(x_i, x_j) = \\exp \\left( - \\frac{ \\left\\Vert x_i - x_j \\right\\Vert^2}{\\sigma^2} \\right)\n",
    "$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import NuSVC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TP**: comparer la méthode SVM à la méthode Naive Bayes sur les 2 jeux de données du cours précédent: détection de langue et classification des types de données."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
