{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Donnée textuelles\n",
    "\n",
    "Projet : classifier un document en fonction de sa langue.\n",
    "\n",
    "Problème de **classification** (et non de régression)\n",
    "\n",
    "## Etape 1\n",
    "- On choisit 2 classes : Anglais et Fançais\n",
    "- Récupérer les données.\n",
    "\n",
    "Mettre les données sous la forme d'un fichier texte avec premier caractère\n",
    "\n",
    "# Etape 2\n",
    "\n",
    "On veut transormer le corpus en vecteur d'entrée X.\n",
    "\n",
    "Le corpus c'est la liste des documents qui contiennent du texte.\n",
    "\n",
    "Les étapes pour vectoriser le texte sont:\n",
    "\n",
    "- enlever la ponctuation\n",
    "- enlever les nombres\n",
    "- enlever \"les trucs bizarres\" : reste balise html, \\\\ ...\n",
    "- on choisit si on travaille avec les mots ou avec les lettres\n",
    "- on choisit si on travaille avec 1-grams, 2-grams, etc.\n",
    "\n",
    "**TP**\n",
    "\n",
    "Ecrire une fonction qui lit un fichier et retourne les vercteur d'entrées et de sortie\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "document fr 7813\n",
      "document en 5102\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "NGRAM_RANGE = (1, 2)\n",
    "\n",
    "vectorizer = CountVectorizer(\n",
    "    input=\"content\",\n",
    "    analyzer=\"word\",\n",
    "    ngram_range=NGRAM_RANGE,\n",
    "    stop_words=None,\n",
    "    binary=True\n",
    ")\n",
    "\n",
    "# l'entrée\n",
    "raw_documents_vector = []\n",
    "\n",
    "# la sortie\n",
    "y_vector = []\n",
    "\n",
    "count_fr = 0\n",
    "count_en = 0\n",
    "\n",
    "for number in \"123\":\n",
    "    file_name = \"./data\"+number+\".txt\"\n",
    "    with open(file_name, \"rt\") as f:\n",
    "        for line in f:\n",
    "            y = line[0]\n",
    "            raw_document = line[2:]\n",
    "            \n",
    "            if y == \"0\":\n",
    "                count_en += 1 \n",
    "            if y == \"1\":\n",
    "                count_fr += 1 \n",
    "            \n",
    "            # je garde les données dans des listes\n",
    "            y_vector.append(int(y))\n",
    "            raw_documents_vector.append(raw_document)\n",
    "   \n",
    "print(\"document fr\", count_fr)\n",
    "vectorizer.fit(raw_documents_vector)\n",
    "print(\"document en\", count_en)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['salut', 'sa', 'farte']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# on verifie le bon fonctionnement\n",
    "tokenizer = vectorizer.build_tokenizer()\n",
    "tokenizer(\"salut sa farte?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dicitur magerit\n",
      "by miner\n",
      "803 algol\n",
      "increased aid\n",
      "complementary role\n",
      "montevideo débarquèrent\n",
      "cruz vraie\n",
      "any offsetting\n",
      "average repair\n",
      "print goodbye\n",
      "insufficient troops\n"
     ]
    }
   ],
   "source": [
    "# on affiche N mots du vocabulaire\n",
    "i_max = 10\n",
    "for i, word in enumerate(vectorizer.vocabulary_.keys()):\n",
    "    if i > i_max:\n",
    "        break\n",
    "    else:\n",
    "        print(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/model_selection/_split.py:2026: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train : 10332\n",
      "test : 2583\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# on créé une instance du classifier\n",
    "clf = MultinomialNB()\n",
    "pipeline_clf = Pipeline(\n",
    "    [\n",
    "        (\"vectorizer\", vectorizer),\n",
    "        (\"clf\", clf)\n",
    "    ]\n",
    ")\n",
    "\n",
    "# on divise nos donnée en 2 population: training/test\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(raw_documents_vector, y_vector, train_size=0.8)\n",
    "\n",
    "print(\"train :\", len(Y_train))\n",
    "print(\"test :\", len(Y_test))\n",
    "\n",
    "# on entraine le classifier\n",
    "pipeline_clf.fit(X_train, Y_train)\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start predict\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "print(\"start predict\")\n",
    "predicted = pipeline_clf.predict(X_test)\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total test : 2583\n",
      "correct : 2572\n",
      "proportion : 0.9957413859852884 0.9957413859852884\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "mean = np.mean(predicted == Y_test)\n",
    "total = len(Y_test)\n",
    "correct_ones = np.sum(predicted == Y_test)\n",
    "print(\"total test :\", total)\n",
    "print(\"correct :\", correct_ones)\n",
    "print(\"proportion :\", mean, float(correct_ones)/total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline_clf.predict([\"bonjour le monde\", \"hello world\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "977 482   \n",
      " 1\n",
      "1055 907     \n",
      " 1\n",
      "1289 486   \n",
      " 1\n",
      "1495 749   \n",
      " 1\n",
      "1502 644   \n",
      " 1\n",
      "1517 737   \n",
      " 1\n",
      "1919 615   \n",
      " 1\n",
      "1961 727  \n",
      " 1\n",
      "1991 Minute    \n",
      " 1\n",
      "2256 Slack    \n",
      " 1\n",
      "2473 Francis Bacon \n",
      " 1\n"
     ]
    }
   ],
   "source": [
    "for i in np.where(predicted != Y_test)[0]:\n",
    "    print(i, X_test[i][0:100], Y_test[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Votre texte est en : Anglais\n"
     ]
    }
   ],
   "source": [
    "text = input(\"saisissez du text : \")\n",
    "lang = \"Français\" if pipeline_clf.predict([text]) else \"Anglais\"\n",
    "print(\"Votre texte est en : \"+lang)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
